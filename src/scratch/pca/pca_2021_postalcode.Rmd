---
title: "PCA 2021"
author: "Jon/Monica"
date: "12/01/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load( tidyverse,naniar,here, dplyr, psych, ggplot2, matlib, corrplot, scales, janitor
                )
```

  the TRANSLATION_MASTER_DEC_2022 only has the CENSUS 2016 DA and postal code. wait?

We can do the imputation and PCA in DA level instead of postal code region level. 

but it is better to do it in postal code level to keep it consistent with previous ses. 

Need a TMF to link to postal code and SD.

The csv file that Roger provided does have the SD. Nice. 





```{r}
# normalizePath(readClipboard(),winslash = "/")
# Lorraine found this new TMF from Roger's folder
new_tmf_2021 = read_csv("K:/15000-40 Development/2023/20230001jd - TMF 202301/gcs_results.csv")
# new_tmf_2021 %>% glimpse()
# Pick up the field from TMF
new_tmf_2021 = new_tmf_2021 %>% mutate(
  DA_ID = paste0("59",
                 str_pad(CD_2021, width = 2, side = "left", pad = "0"),
                 str_pad(DA_2021, width = 4, side = "left", pad = "0") )
) 

new_tmf_2021 = new_tmf_2021 %>% 
  filter(!is.na(DA_2021))
```

# Load data and exclude ID and area variables

```{r}
# data = readRDS('../Impute/data_imputed_knn_2021.rds')
data = data_imputed_2021 %>% 
  mutate(DA_ID = as.character(DA_ID)) %>% 
  inner_join(
      
    new_tmf_2021 %>%
  select(
    DA_ID,
    POSTAL_CODE = POSTALCODE,
    REGION = MUN_NAME_2021,
	DISTRICT_NUMBER = SD,
    LATITUDE,
    LONGITUDE
  ) ,
  by = c("DA_ID")
    
  ) %>% 
  mutate(
    DISTRICT_NUMBER = str_pad(DISTRICT_NUMBER, width = 2, side = "left", pad = "0")
    # LATITUDE = as.character(LATITUDE),
    # LONGITUDE = as.character(LONGITUDE)
  )
    
    

  
data$AGE_GRP_00_14 = data$AGE_GRP_00_04 + data$AGE_GRP_05_09 + data$AGE_GRP_10_14
nrow(data)
```
120847



If POSTAL_CODE is not unique, it needs to pad with CD_ID to get unique id. 

```{r}
# colnames(data)

data %>% 
  tabyl(POSTAL_CODE ) %>% 
  filter(n>1)
```

```{r}
# DA and postal code map
# da_pc_map <- data %>% select(c("DA_ID", "POSTAL_CODE"))
```

```{r}
data_da <- data %>% select(-c("CSD_UID", "CD_UID", "DA_ID"
# "POSTAL_CODE", "REGION", "SD", "LATITUDE", "LONGITUDE"
))
data_da_unique <- unique(data_da)
nrow(data_da_unique)
```


# Drop ID variables and keep numeric ones

```{r}
pacman::p_load(
  rio,           # import/export
  tidyverse,     # data mgmt and viz
  naniar,        # assess and visualize missingness
  mice ,          # missing data imputation
  psych
)
# all_vars <- data_da_unique %>% select(-c("DA_ID"))
# all_vars$AGE_GRP_00_14 = all_vars$AGE_GRP_00_04 + all_vars$AGE_GRP_05_09 + all_vars$AGE_GRP_10_14

# it is weird that it create NA cor between these two variables. 
# data %>% #select(OCC_TRADES ,GO_TO_WORK_7AM_9AM) %>% 
  # slice(593) 
  # glimpse()
# %>% cor()
  # cor(method = "pearson", use = "pairwise.complete.obs")
  # glimpse()

     


```
There is a "Inf" in row 593 for OCC_TRADE.


Inf represents an infinite value, such as when you divide a number by 0.

 is.infinite() and is.finite().
 
 
 
```{r}
data %>% 
  summarise(
    across(
      .cols = everything(),
      .fns = ~sum(is.infinite(.x))
    )
  ) %>% 
  pivot_longer(
    cols = everything()
    
  ) %>% 
  filter(value >0)
```
 
 It is weird that 
 
name<chr> value<int>
COUPLES_CHILD_N	2			
OCC_TRADES	1			
GO_TO_WORK_7AM_9AM	1			
POP_PCT_CHANGE	27
 
 
 Should repalce those Inf with zeros?
 
```{r}
# data %>% 
#   filter(
#     is.infinite(GO_TO_WORK_7AM_9AM)
#   )


```
 
 59410254
 
Those Inf should be imputed at the previous step. 
 
```{r}
data %>% 
  select(starts_with("OCC")) %>% 
  names()
```
 

# Use variables from Tanvir and Jon's 2016 model

```{r}
occupation = c('OCC_MGMT', 'OCC_BUS_FIN_AD',
               'OCC_NAT_APP_SCI', 'OCC_HLTH',
               'OCC_SOCI_SERV', 'OCC_ART_CUL_REC','OCC_SALE_SERV',
               'OCC_TRADES', 'OCC_NAT_RSRC', 'OCC_MAN_UTIL')

```


```{r}
data %>% 
  select(starts_with("EDUC"))
```


```{r}
education = c('EDUC_NONE',
              'EDUC_HIGHSCH',
              'EDUC_POSTSEC',
              # 'EDUC_COLLEGE',
              'EDUC_BACHELOR', 
              # 'EDUC_TRADES', 
              # 'EDUC_CRT_ABV_BACH',
              'EDUC_MEDICAL',
              'EDUC_MASTERS', 
              'EDUC_PHD')
```


```{r}
economics = c('HOME_VALUE_MED', 'HOME_VALUE_AVG', 
              'HOME_RENT_MED', 'HOME_RENT_AVG',
              'INC_AT_FAM_MED', 'INC_AT_FAM_AVG', 
              'LABOUR_EMPL_RT', 'LABOUR_PART_RT',
              "INC_FAM_TOP","INC_FAM_DEC_10",
              "INC_HHS_100K_125K","INC_HHS_125K_150K","INC_HHS_150K_PLUS",
              'INC_AT_LONE_PARENT_MED','INC_AT_LONE_PARENT_AVG',  
              'INC_AT_CPL_W_CHILD_MED', 'INC_AT_CPL_W_CHILD_AVG', 
              'REPAIRS_MINOR',
              'LIM_AT_PREVALENCE','LICO_AT_PREVALENCE',
              'SUBSIDIZED_HOUS')
```


```{r}
family = c('SING_PARENT_F', 'SING_PARENT_M',
           'COUPLES_CHILD_Y',
           'HOME_SUITABLE_NO',
           'MARITAL_MARR','MARITAL_DIV', 
           'FAM_SIZE_5')
```


```{r}

data = data %>% 
  mutate(
    GO_TO_WORK_5AM_9AM = GO_TO_WORK_5AM_6AM + GO_TO_WORK_6AM_7AM+GO_TO_WORK_7AM_8AM+GO_TO_WORK_8AM_9AM,
    AGE_GRP_00_19 = AGE_GRP_00_04 + AGE_GRP_05_09+AGE_GRP_10_14+AGE_GRP_15_19,
    AGE_GRP_20_65 = AGE_GRP_20_24 + AGE_GRP_25_29+AGE_GRP_30_34+AGE_GRP_35_39+
    AGE_GRP_40_44 + AGE_GRP_45_49+AGE_GRP_50_54+AGE_GRP_55_59+AGE_GRP_60_64
    
    
  )
#  It is weird that age group and go to work group have many NA loading, have to aggregate them to a few groups to get PCA working. 
community = c(
  'POP_DENSITY',
  'AVG_AGE',
  'DWELL_HOUS',
  'DWELL_APT_LRG',
  'ABORIGINAL_YES',
  'REG_INDIAN_YES',
  'CITIZEN_CAN',
  'IMMIGRANT_YES',
  'MINORITY_YES',
   'HOME_OWN_OWN',
  'LANG_SPOKE_NONE',

  'COMMUTE_DURATION_15M_LESS',
  'COMMUTE_DURATION_15_29M',
  'COMMUTE_DURATION_30_44M',
  'COMMUTE_DURATION_45_59M',
  'COMMUTE_DURATION_60M_OVER',
  
  # 'GO_TO_WORK_5AM_6AM',
  # 'GO_TO_WORK_6AM_7AM',
  # 'GO_TO_WORK_7AM_8AM',
  # 'GO_TO_WORK_8AM_9AM',
  'GO_TO_WORK_5AM_9AM',
  'GO_TO_WORK_9AM_12PM',
  'GO_TO_WORK_12PM_4AM',
  
  # 'AGE_GRP_00_14',
  # 'AGE_GRP_15_19',
  #  'AGE_GRP_55_59',
  # 'AGE_GRP_55_59',
  # 'AGE_GRP_60_64',
  # 'AGE_GRP_65_PLUS',
  # 'AGE_GRP_00_04',
  # 'AGE_GRP_05_09',
  # 'AGE_GRP_10_14',
  # 'AGE_GRP_15_19',
  # 'AGE_GRP_20_24',
  # 'AGE_GRP_25_29',
  # 'AGE_GRP_30_34',
  # 'AGE_GRP_35_39',
  # 'AGE_GRP_40_44',
  # 'AGE_GRP_45_49',
  # 'AGE_GRP_50_54',
  # 'AGE_GRP_55_59',
  # 'AGE_GRP_60_64',
  
  'AGE_GRP_00_19',
  'AGE_GRP_20_65',
  'AGE_GRP_40_44'
  # 'AGE_GRP_65_PLUS'
  
  # 'MAJOR_EDUC',
  # 'MAJOR_ART_COM',
  # 'MAJOR_HUMANITIES',
  # 'MAJOR_SOC_SCI',
  # 'MAJOR_BUS_MGT',
  # 'MAJOR_PHY_SCI',
  # 'MAJOR_MATH_COMP',
  # 'MAJOR_ENGR',
  # 'MAJOR_NAT_RSRC',
  # 'MAJOR_HLTH',
  # 'MAJOR_SERVICES'
)

# 
# 
# community = c(
#   'POP_DENSITY',
#   "AVG_AGE",
#   'ABORIGINAL_YES',
#   'REG_INDIAN_YES',
#   'CITIZEN_CAN',
#   'IMMIGRANT_YES',
#   'LANG_SPOKE_NONE',
#     'HOME_OWN_OWN',
# 
#   'COMMUTE_DURATION_15M_LESS',
#   'COMMUTE_DURATION_15_29M',
#   'COMMUTE_DURATION_30_44M',
#   'COMMUTE_DURATION_45_59M',
#   'COMMUTE_DURATION_60M_OVER',
#   
#   'GO_TO_WORK_5AM_6AM',
#   'GO_TO_WORK_6AM_7AM',
#   'GO_TO_WORK_7AM_8AM',
#   'GO_TO_WORK_8AM_9AM',
#   'GO_TO_WORK_9AM_12PM',
#   'GO_TO_WORK_12PM_4AM',
#   
#   'AGE_GRP_00_14',
#   'AGE_GRP_15_19',
#   'AGE_GRP_55_59',
#   'AGE_GRP_60_64',
#   'AGE_GRP_65_PLUS',
#   'MAJOR_EDUC',
#   'MAJOR_ART_COM',
#   'MAJOR_HUMANITIES',
#   'MAJOR_SOC_SCI',
#   'MAJOR_BUS_MGT',
#   'MAJOR_PHY_SCI',
#   'MAJOR_MATH_COMP',
#   'MAJOR_ENGR',
#   'MAJOR_NAT_RSRC',
#   'MAJOR_HLTH',
#   'MAJOR_SERVICES'
# )
```



```{r}
ses_vars_vec = c(occupation,
                 education,
                 economics,
                 family,
                 community)

ses_vars <- data %>% select(all_of(ses_vars_vec))

nrow(ses_vars)
```
No missing value
# PCA Preamble

## 1. Scale the data using scale()

```{r}
scale_ses_vars = scale(ses_vars)
gg_miss_var(ses_vars, show_pct = TRUE)
```

## 2. Check correlation matrix of scaled variables

```{r}
corr_matrix <- scale_ses_vars %>% cor(use = 'complete.obs')
```

```{r}
# check if corr matrix invertible
# corr_matrix_inv  <- matlib::inv(corr_matrix)
```

## 3. Test for equal variances (Bartlett)

```{r}
bartlett <- psych::cortest.bartlett(corr_matrix) # chi-sq test
print(bartlett)

# kmo <- psych::KMO(scale_all_vars)
# print(kmo)
```

## 4. Model 1 (prelim) - unrotated

```{r}
pc1 <- psych::principal(ses_vars %>% 
                       na.omit() %>% scale(),
                       nfactors = length(ses_vars), 
                       rotate="none")

plot(pc1$values, type = 'b')
```

## 5. Model 2 - [Kaiser-Varimax rotation](https://www.statisticshowto.datasciencecentral.com/varimax-rotation-definition/)

```{r}
pc2 <- psych::principal(ses_vars %>% na.omit() %>% scale(), nfactors=1, 
                        rotate = "varimax", scores = TRUE)
```


```{r}
plot(pc1$values, type = 'b')
```


# Functions

## Check PCA

```{r}
# check and get the PCA
check_pca = function(dataset){
  data_matrix =  dataset%>% # Create matrix: some tests will require it 
   cor(use = 'complete.obs')
   # See intercorrelations
  print('corr_matrix:')
  print(round(data_matrix, 2))
 
  # Bartlett's
  print("Bartlett's test:")
  print(psych::cortest.bartlett(dataset))
   
  # KMO<span> (Kaiser-Meyer-Olkin)</span>
  print("Kaiser-Meyer-Olkin test")
  print(psych::KMO(data_matrix))
  
  # Start off with unrotated PCA
 
  pc1 = psych::principal(dataset %>% 
                           na.omit() %>% scale(),
                         nfactors = length(dataset), 
                         rotate="none")
  print("Start off with unrotated PCA")
  print(pc1)
  print("First Scree Plot")
  plot(pc1$values[0:5], type = 'b', xlab = "PC #", ylab = "Amount of explained variance", main = "Screeplot of the first 5 PCs") # scree plot
  abline(h = 1, col="red", lty=5)
  legend("topright", legend=c("Eigenvalue = 1"),
         col=c("red"), lty=5, cex=0.6)
  
  cumpro <- cumsum(pc1$values / sum(pc1$values)) # cumulative variance
  plot(cumpro[0:5], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
  abline(v = 3, col="blue", lty=5)
  abline(h = 0.8775, col="blue", lty=5)
  legend("topleft", legend=c("Cut-off @ PC3"),
         col=c("blue"), lty=5, cex=0.6)
}
```

## Generate PCA (rotated)

```{r}
gen_pca = function(dataset = ses_vars[occupation], model_name = "Occupation Index"){
    # Now with varimax rotation, Kaiser-normalized 
  # by default:
  print("Now with varimax rotation, Kaiser-normalized ")
  pc2 = psych::principal(dataset %>% scale(), nfactors=1, 
  rotate = "varimax", scores = TRUE)
  saveRDS(pc2, file = glue::glue("{model_name}.rds"))
  print("Resulted PC")
  # print(pc2)
  print(summary(pc2))
  print("Results loadings")
  print(pc2$loadings)
  as.data.frame(unclass(pc2$loadings))%>% 
  rownames_to_column(var = "variable") %>% 
    write_csv(glue::glue("{model_name}_loadings.csv"))
  
  # Healthcheck
  print( "Healthcheck")
  print("residual:")
  print(pc2$residual)
  print("fit:")
  print(pc2$fit)
  print("communality:")
  print(pc2$communality)

  # return scores in the dataset
  print("return scores  in the dataset")
  dataset = cbind(dataset, scale(pc2$scores))
  print("summary")
  print(summary(dataset))
  return(dataset)
}
```

# Run PCA on variable groups to create subindices

## 1. Occupation Index

```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(ses_vars[occupation]), method="ellipse")
```

```{r}
check_pca(ses_vars[occupation])

occ_matrix = gen_pca(ses_vars[occupation], model_name = "Occupation Index")
# occ_matrix %>% str()
# Append the score back to ses_vars dataframe
ses_vars$occ_idx = occ_matrix$PC1
```


## 2. Education Index

```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(ses_vars[education]), method="ellipse")
```

```{r}
check_pca(ses_vars[education])

educ_matrix = gen_pca(ses_vars[education], model_name = "Education Index")

# Append the score back to ses_vars dataframe
ses_vars$educ_idx = educ_matrix$PC1
```

## 3. Economics Index

```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(ses_vars[economics]), method="ellipse", tl.cex = 0.75)
```

```{r}
check_pca(ses_vars[economics])
# economics[20] this vairable "LICO_AT_PREVALENCE" gets zero loading or NULL. 
econ_matrix = gen_pca(ses_vars[economics[-20]], model_name = "Economics Index")

# Append the score back to ses_vars dataframe
ses_vars$econ_idx = econ_matrix$PC1
```

## 4. Family Index

```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(ses_vars[family]), method="ellipse")
```


```{r}
check_pca(ses_vars[family])
# family[-3] COUPLES_CHILD_Y % of family with couples with child decreases the performance of PCA. 
fam_matrix = gen_pca(ses_vars[family[-3]], model_name = "Family Index")

# Append the score back to ses_vars dataframe
ses_vars$fam_idx = fam_matrix$PC1
```

```{r}
ses_vars[family] %>% glimpse()
```

The percentage of single parents family, percentage of couples with children, if home is suitable to live. 

## 5. Community Index

```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(ses_vars[community]), method="ellipse", tl.cex=0.6)
```

```{r}


data %>%  # select(starts_with("MAJOR")) %>% 
  glimpse()

imp_missing_cols_2021 <- miss_var_summary(data[community]
                                            , show_pct = 1) 
# check_pca(ses_vars[community])

# ses_vars %>% 
# community[]
comm_matrix = gen_pca(data[community], model_name = "Community Index");

# Append the score back to ses_vars dataframe
ses_vars$comm_idx = comm_matrix$PC1
```


# Composite Index: run PCA on subindices

```{r}
subindices_names = c("educ_idx", "occ_idx" ,  "econ_idx" , "fam_idx", "comm_idx")

subindices <- ses_vars %>% select(all_of(subindices_names))
```


```{r}
# plot correlation matrix for fun
corrplot::corrplot(cor(subindices), method="ellipse")
```

```{r}
cor(subindices)
```


```{r}
check_pca(subindices)

composite_matrix <- gen_pca(subindices, model_name = "Composite Index")

# Append the score back to ses_vars dataframe
ses_vars$composite_idx = composite_matrix$PC1
```

```{r}
data %>% glimpse()
```



# Overall Index: run PCA on all variables, not subindices

```{r}
check_pca(ses_vars%>% select(-contains("_idx")))

overall_matrix <- gen_pca(ses_vars %>% select(-contains("_idx")) %>% 
                            select(
                              -COMMUTE_DURATION_60M_OVER,
                              - DWELL_APT_LRG,
                              - HOME_SUITABLE_NO,
                              - INC_AT_LONE_PARENT_AVG, 
                              -COUPLES_CHILD_Y,
                              -AVG_AGE, 
                              - CITIZEN_CAN, 
                              - LICO_AT_PREVALENCE
                            ) , model_name = "Overall Index");
# Not converge, no usefule
# Append the score back to ses_vars dataframe
ses_vars$overall_idx = overall_matrix$PC1
```

```{r}

ses_vars <- ses_vars %>% 
  mutate(DA_ID = data$DA_ID,
         CD_UID = data$CD_UID)
  # cbind(data$DA_ID, ses_vars)
# colnames(ses_vars)[1] <- c("DA_ID")
ses_vars %>% nrow()
```


# Merge back to original data and sanity check

```{r}


ses_index <- ses_vars %>% select(c(#"DA_ID", "CD_UID",
                                   "educ_idx", "occ_idx" ,
                                   "econ_idx" , "fam_idx", "comm_idx",
                                   "composite_idx", "overall_idx"))

ses_index %>% nrow()
data %>% nrow()
data %>% glimpse()
data_ses <- bind_cols(data, ses_index )
# data_ses = left_join(data, ses_index, by =c("DA_ID", "CD_UID"))
data_ses %>% nrow()
# the combination of c("DA_ID", "CD_UID") is not unique as well. ???? 

data_ses %>% write_csv("../../Data/ses_2021_postalcode.csv")

data_ses = read_csv("../../Data/ses_2021_postalcode.csv")

data_ses %>% glimpse()
```




https://www150.statcan.gc.ca/n1/pub/92-195-x/2011001/geo/da-ad/def-eng.htm

59331584	

Province 59:
CD 09:
DA 0103


If we want to let each postal code has a SES, we need to do the imputation again. 

First, we need to get the postal code list from student enrollment table. 

Many DA has zero population in census 2021, and those DA may not be useful for our students


```{r}
# new_tmf_2021 %>% filter(!is.na(DA_2021)) %>% pull(POSTALCODE) %>% n_distinct()
```
133006 postal code. 


This problem should be solved in different step in another file. 

```{r}
# -- EDW2 Headcount at student level
# distinct_postal_code_query  = "
# Select distinct fe.postal_code
# from edw2_query.f_enrolment fe 
# inner join edw2_query.d_date dd on dd.d_date_key = fe.d_date_key 
# inner join edw2_query.d_student ds on ds.d_student_key = fe.d_student_key
# inner join edw2_query.d_school dsh on dsh.d_school_key = fe.d_school_historical_key 
# inner join edw2_query.d_student_demographic dsd on dsd.d_student_demographic_key = fe.d_student_demographic_key 
# inner join edw2_query.d_enrolment_demographic ded on ded.d_enrolment_demographic_key = fe.d_enrolment_demographic_key
# inner join edw2_query.d_special_need dspnd on dspnd.d_special_need_key = fe.d_special_need_key
# where
#       ded.grade_description_legacy != 'Home School Student' 
#       and dsd.age_group_at_dec_31 not in ('Under 5', '(Unspecified)') 
#       and dsd.Age_Group_At_Jun_30 not in ('Under 5', '(Unspecified)')
#       and ded.authority_enrolment = 'Authority School' 
#       and dsh.school_type_group = 'BC School'     
#       and dsh.school_type in ('BC Public School','BC Independent School')
#       and dd.month_long = 'September'
#       and dd.school_year >= '2018/2019'
#       "
# 
# source("c:/app/r/r_utility.r")
# con = connect_edw("edw")
# 
# distinct_postal_code_db = get_db(distinct_postal_code_query, con)
# distinct_postal_code_df = distinct_postal_code_db %>% collect()
# 
# distinct_postal_code_df %>% glimpse()

```

101,445 distinct postal code in student enrollment table. 






2. a short postal code talbe in 

	CENSUS_YEAR, 
	POSTAL_CODE, 
	DISTRICT_NUMBER, 
	DISTRICT_NAME, 
	DISSEMINATION_AREA_ID, 
	CENSUS_SUBDIVISION_ID, 
	CENSUS_DISTRICT_ID, 
	CENSUS_REGION, 
	LATITUDE, 
	LONGITUDE, 
	GROSS_MEDIAN_FAMILY_INCOME, 
	GROSS_AVERAGE_FAMILY_INCOME, 
	SES_INDEX, 
	EDUCATION_INDEX, 
	OCCUPATION_INDEX, 
	ECONOMIC_INDEX, 
	FAMILY_INDEX, 
	COMMUNITY_INDEX, 
	EDW_UPDATED_DATE, 
	EDW_CREATED_BY, 
	EDW_UPDATED_BY, 
	EDW_JOB_NAME
	
	3. a short postal code table in edw_research: ECON_SES_INC_IMP_ALL_YEARS
	
		CENSUS_YEAR, 
	POSTAL_CODE, 
	DISTRICT_NUMBER, 
	DA_ID, 
	CSD_UID, 
	CD_UID, 
	REGION, 
	LATITUDE, 
	LONGITUDE, 
	FAM_INC_MED, 
	FAM_INC_AVG, 
	SES_IDX, 
	EDUC_IDX, 
	OCC_IDX, 
	ECON_IDX, 
	FAM_IDX, 
	COMM_IDX




```{r}

# Join two table together

data_ses_2021_postal_code_append = data_ses %>% 
  
  janitor::clean_names(case = "all_caps")  %>% 
#   select(
# 	CENSUS_YEAR,
# 
# 	DA_ID,
# 	CD_UID,
# 	CSD_UID,
# 
# 	FAM_INC_MED = INC_AT_FAM_MED         ,  # Brett noticed that the income is lower than BT before tax
# 	FAM_INC_AVG = INC_AT_FAM_AVG         ,
# 	SES_IDX = COMPOSITE_IDX,
# 	EDUC_IDX,
# 	OCC_IDX,
# 	ECON_IDX,
# 	FAM_IDX,
# 	COMM_IDX
# 
#   ) %>%
#   mutate(
#     DA_ID = as.character(DA_ID),
#     # SD = str_pad(SD, width = 3, side = "left", pad = "0")
#   ) %>%
#   left_join(
# 
#     new_tmf_2021 %>%
#   select(
#     DA_ID,
#     POSTAL_CODE = POSTALCODE,
#     REGION = MUN_NAME_2021,
# 	 DISTRICT_NUMBER = SD,
#     LATITUDE,
#     LONGITUDE
#   ) ,
#   by = c("DA_ID")
# 
#   ) %>%
  mutate(
    DISTRICT_NUMBER = str_pad(DISTRICT_NUMBER, width = 3, side = "left", pad = "0")
    # LATITUDE = as.character(LATITUDE),
    # LONGITUDE = as.character(LONGITUDE)
  ) %>%
  select(
  CENSUS_YEAR, 
	POSTAL_CODE , 
	DISTRICT_NUMBER, 
	DA_ID, 
	CSD_UID, 
	CD_UID, 
	REGION, 
	LATITUDE, 
	LONGITUDE, 
	FAM_INC_MED = INC_AT_FAM_MED         ,  # Brett noticed that the income is lower than BT before tax
	FAM_INC_AVG = INC_AT_FAM_AVG         ,
	SES_IDX = COMPOSITE_IDX,
	EDUC_IDX, 
	OCC_IDX, 
	ECON_IDX, 
	FAM_IDX, 
	COMM_IDX
  ) 

data_ses_2021_postal_code_append %>% 
  glimpse()
# 121,762
# append to table: ECON_SES_INC_IMP_ALL_YEARS


```

	
```{r}

```
	




```{r}
distinct_postal_code_df %>% 
  glimpse()
```





```{r}
postal_code_ses_2018_2022 = distinct_postal_code_df %>% 
  left_join(
    data_ses %>% 
  mutate(DA_ID = as.character(DA_ID)),
        by = c("DA_ID")
  )
```


```{r}
postal_code_ses_2018_2022 %>% glimpse()
```



```{r}
data_ses_postal_code %>% write_csv("../../Data/ses_2021_postal_code.csv")
```


Some DAs miss Postal code which need be fixed. 


```{r}
data_ses_postal_code %>% gg_miss_var( show_pct = TRUE)
```



```{r}
ses_by_region <- data %>% 
  select(SD, composite_idx, INC_AT_FAM_AVG) %>%
  group_by(SD) %>%
  summarize(mean_composite = mean(composite_idx, na.rm = TRUE), mean_income = mean(INC_AT_FAM_AVG, na.rm = TRUE))
```

```{r}
#devtools::install_github('cttobin/ggthemr', force = TRUE)
library(ggthemr)
library(scales)
ggthemr('fresh')

ggplot(ses_by_region, aes(x = mean_income, y = mean_composite)) +
    geom_point(size=3) + geom_text(aes(label = SD), nudge_y = 0.2) + 
  ggtitle("2016 Socioeconomic Status Index, School Districts") +
  xlab("Average family income") + ylab("Socioeconomic status index") +
  scale_x_continuous(labels = comma)
```

```{r}
# save SES indices to rds
ses_by_postal_code <- data %>% select(c("POSTAL_CODE","SD", "DA_ID", "CSD_UID", "CD_UID", "REGION", 
                               "LATITUDE", "LONGITUDE",
                               "educ_idx", "occ_idx",
                               "econ_idx" , "fam_idx", "comm_idx",
                               "composite_idx", "overall_idx"))

saveRDS(ses_by_postal_code, "ses_2021_by_postal_code.rds")
```






```{r}
new_tmf_2021 %>% 
  write_csv("../../Data/TMF_2021.csv")
```





